{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d83745",
   "metadata": {},
   "source": [
    "# ML Data Preparation Pipeline\n",
    "\n",
    "## Purpose\n",
    "This notebook prepares and cleans the healthcare claims dataset for machine learning modeling. It processes the input dataset `outputs/claims_with_policy_rules.csv` to create a clean, ML-ready dataset with standardized features.\n",
    "\n",
    "## Key Objectives\n",
    "1. Load and validate the input dataset\n",
    "2. Select relevant features for ML modeling\n",
    "3. Clean and standardize column names\n",
    "4. Handle missing values and data type corrections\n",
    "5. Save the final ML-ready dataset to `outputs/ml_outputs/`\n",
    "\n",
    "## Input/Output Structure\n",
    "- **Input**: `outputs/claims_with_policy_rules.csv`\n",
    "- **Output**: `outputs/ml_outputs/final_ml_ready_claims.csv`\n",
    "- **Working Directory**: `notebooks-02/`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa84834",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7aec1803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.2\n",
      "NumPy version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f348722",
   "metadata": {},
   "source": [
    "## Step 2: Setup Directory Structure and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cf1021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/kxshrx/asylum/healix\n",
      "Input file: /Users/kxshrx/asylum/healix/outputs/claims_with_policy_rules.csv\n",
      "ML outputs directory: /Users/kxshrx/asylum/healix/outputs/ml_outputs\n",
      "Output file: /Users/kxshrx/asylum/healix/outputs/ml_outputs/final_ml_ready_claims.csv\n",
      "\n",
      "Input file exists: True\n",
      "ML outputs directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Define project paths\n",
    "project_root = Path().resolve().parent  # Go up from notebooks-02 to project root\n",
    "input_file = project_root / \"outputs\" / \"claims_with_policy_rules.csv\"\n",
    "ml_outputs_dir = project_root / \"outputs\" / \"ml_outputs\"\n",
    "output_file = ml_outputs_dir / \"final_ml_ready_claims.csv\"\n",
    "\n",
    "# Create ml_outputs directory if it doesn't exist\n",
    "ml_outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Input file: {input_file}\")\n",
    "print(f\"ML outputs directory: {ml_outputs_dir}\")\n",
    "print(f\"Output file: {output_file}\")\n",
    "print(f\"\\nInput file exists: {input_file.exists()}\")\n",
    "print(f\"ML outputs directory exists: {ml_outputs_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cd5cf",
   "metadata": {},
   "source": [
    "## Step 3: Load Input Dataset with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64127a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /Users/kxshrx/asylum/healix/outputs/claims_with_policy_rules.csv\n",
      "Successfully loaded dataset with shape: (222000, 33)\n",
      "Successfully loaded dataset with shape: (222000, 33)\n"
     ]
    }
   ],
   "source": [
    "# Load the input dataset with proper error handling\n",
    "try:\n",
    "    print(f\"Loading dataset from: {input_file}\")\n",
    "    df_raw = pd.read_csv(input_file)\n",
    "    print(f\"Successfully loaded dataset with shape: {df_raw.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_file}\")\n",
    "    print(\"Please ensure the claims_with_policy_rules.csv file exists in the outputs directory.\")\n",
    "    raise\n",
    "    \n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The input file appears to be empty.\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbe686",
   "metadata": {},
   "source": [
    "## Step 4: Initial Dataset Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a44e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIAL DATASET INVESTIGATION\n",
      "============================================================\n",
      "\n",
      "Dataset Shape: 222,000 rows × 33 columns\n",
      "\n",
      "Column Names:\n",
      " 1. claim_id\n",
      " 2. patient_hash\n",
      " 3. age\n",
      " 4. gender\n",
      " 5. blood_type\n",
      " 6. medical_condition\n",
      " 7. admission_year_month\n",
      " 8. admission_type\n",
      " 9. length_of_stay_days\n",
      "10. discharge_date\n",
      "11. medication\n",
      "12. test_results\n",
      "13. insurance_provider\n",
      "14. billing_amount\n",
      "15. created_at\n",
      "16. provider_id\n",
      "17. plan_type\n",
      "18. coverage_percentage\n",
      "19. max_coverage_amount\n",
      "20. copay_percentage\n",
      "21. deductible_amount\n",
      "22. annual_out_of_pocket_max\n",
      "23. excluded_conditions\n",
      "24. medication_coverage\n",
      "25. diagnostic_test_coverage\n",
      "26. admission_type_rules\n",
      "27. waiting_period\n",
      "28. pre_existing_condition_coverage\n",
      "29. network_coverage\n",
      "30. emergency_coverage\n",
      "31. preventive_care_coverage\n",
      "32. data_source\n",
      "33. policy_id\n",
      "\n",
      "Data Types:\n",
      "claim_id                             int64\n",
      "patient_hash                        object\n",
      "age                                  int64\n",
      "gender                              object\n",
      "blood_type                          object\n",
      "medical_condition                   object\n",
      "admission_year_month                object\n",
      "admission_type                      object\n",
      "length_of_stay_days                  int64\n",
      "discharge_date                      object\n",
      "medication                          object\n",
      "test_results                        object\n",
      "insurance_provider                  object\n",
      "billing_amount                     float64\n",
      "created_at                          object\n",
      "provider_id                          int64\n",
      "plan_type                           object\n",
      "coverage_percentage                float64\n",
      "max_coverage_amount                 object\n",
      "copay_percentage                   float64\n",
      "deductible_amount                  float64\n",
      "annual_out_of_pocket_max            object\n",
      "excluded_conditions                 object\n",
      "medication_coverage                 object\n",
      "diagnostic_test_coverage           float64\n",
      "admission_type_rules                object\n",
      "waiting_period                       int64\n",
      "pre_existing_condition_coverage      int64\n",
      "network_coverage                    object\n",
      "emergency_coverage                  object\n",
      "preventive_care_coverage           float64\n",
      "data_source                         object\n",
      "policy_id                            int64\n",
      "dtype: object\n",
      "\n",
      "Missing Data Summary:\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Print comprehensive dataset information\n",
    "print(\"=\" * 60)\n",
    "print(\"INITIAL DATASET INVESTIGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset Shape: {df_raw.shape[0]:,} rows × {df_raw.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df_raw.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "print(\"\\nMissing Data Summary:\")\n",
    "missing_summary = df_raw.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary)\n",
    "    print(f\"\\nTotal missing values: {df_raw.isnull().sum().sum():,}\")\n",
    "    print(f\"Percentage of missing data: {(df_raw.isnull().sum().sum() / (df_raw.shape[0] * df_raw.shape[1]) * 100):.2f}%\")\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8af539",
   "metadata": {},
   "source": [
    "## Step 5: Define ML Feature Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e8f560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 25 ML feature columns:\n",
      " 1. age\n",
      " 2. gender\n",
      " 3. blood_type\n",
      " 4. medical_condition\n",
      " 5. admission_type\n",
      " 6. length_of_stay_days\n",
      " 7. medication\n",
      " 8. test_results\n",
      " 9. insurance_provider\n",
      "10. billing_amount\n",
      "11. plan_type\n",
      "12. coverage_percentage\n",
      "13. max_coverage_amount\n",
      "14. copay_percentage\n",
      "15. deductible_amount\n",
      "16. annual_out_of_pocket_max\n",
      "17. excluded_conditions\n",
      "18. medication_coverage\n",
      "19. diagnostic_test_coverage\n",
      "20. admission_type_rules\n",
      "21. waiting_period\n",
      "22. pre_existing_condition_coverage\n",
      "23. network_coverage\n",
      "24. emergency_coverage\n",
      "25. preventive_care_coverage\n",
      "\n",
      "Available columns (25): ['age', 'gender', 'blood_type', 'medical_condition', 'admission_type', 'length_of_stay_days', 'medication', 'test_results', 'insurance_provider', 'billing_amount', 'plan_type', 'coverage_percentage', 'max_coverage_amount', 'copay_percentage', 'deductible_amount', 'annual_out_of_pocket_max', 'excluded_conditions', 'medication_coverage', 'diagnostic_test_coverage', 'admission_type_rules', 'waiting_period', 'pre_existing_condition_coverage', 'network_coverage', 'emergency_coverage', 'preventive_care_coverage']\n",
      "\n",
      "All 25 feature columns are available in the dataset!\n"
     ]
    }
   ],
   "source": [
    "# Define the final ML feature column list (refined set)\n",
    "ml_feature_columns = [\n",
    "    # Patient demographics and medical info\n",
    "    'age',\n",
    "    'gender', \n",
    "    'blood_type',\n",
    "    'medical_condition',\n",
    "    \n",
    "    # Admission and stay details\n",
    "    'admission_type',\n",
    "    'length_of_stay_days',\n",
    "    \n",
    "    # Medical treatment\n",
    "    'medication',\n",
    "    'test_results',\n",
    "    \n",
    "    # Insurance and billing\n",
    "    'insurance_provider',\n",
    "    'billing_amount',\n",
    "    \n",
    "    # Policy details\n",
    "    'plan_type',\n",
    "    'coverage_percentage',\n",
    "    'max_coverage_amount',\n",
    "    'copay_percentage',\n",
    "    'deductible_amount',\n",
    "    'annual_out_of_pocket_max',\n",
    "    \n",
    "    # Coverage rules\n",
    "    'excluded_conditions',\n",
    "    'medication_coverage',\n",
    "    'diagnostic_test_coverage',\n",
    "    'admission_type_rules',\n",
    "    'waiting_period',\n",
    "    'pre_existing_condition_coverage',\n",
    "    'network_coverage',\n",
    "    'emergency_coverage',\n",
    "    'preventive_care_coverage'\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(ml_feature_columns)} ML feature columns:\")\n",
    "for i, col in enumerate(ml_feature_columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# Check which columns are available in the dataset\n",
    "available_columns = [col for col in ml_feature_columns if col in df_raw.columns]\n",
    "missing_columns = [col for col in ml_feature_columns if col not in df_raw.columns]\n",
    "\n",
    "print(f\"\\nAvailable columns ({len(available_columns)}): {available_columns}\")\n",
    "if missing_columns:\n",
    "    print(f\"\\nMissing columns ({len(missing_columns)}): {missing_columns}\")\n",
    "else:\n",
    "    print(f\"\\nAll {len(ml_feature_columns)} feature columns are available in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bd902",
   "metadata": {},
   "source": [
    "## Step 6: Drop Non-Essential Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5359660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 33 columns\n",
      "Target ML features: 25 columns\n",
      "Columns to drop: 8 columns\n",
      "\n",
      "Dropping the following columns:\n",
      " 1. claim_id\n",
      " 2. patient_hash\n",
      " 3. admission_year_month\n",
      " 4. discharge_date\n",
      " 5. created_at\n",
      " 6. provider_id\n",
      " 7. data_source\n",
      " 8. policy_id\n",
      "\n",
      "Successfully dropped 8 columns\n",
      "New dataset shape: (222000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Identify columns to drop (everything not in the ML feature list)\n",
    "columns_to_drop = [col for col in df_raw.columns if col not in ml_feature_columns]\n",
    "\n",
    "print(f\"Original dataset: {df_raw.shape[1]} columns\")\n",
    "print(f\"Target ML features: {len(available_columns)} columns\")\n",
    "print(f\"Columns to drop: {len(columns_to_drop)} columns\")\n",
    "\n",
    "if columns_to_drop:\n",
    "    print(\"\\nDropping the following columns:\")\n",
    "    for i, col in enumerate(columns_to_drop, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    # Create a copy with only the required columns\n",
    "    df_ml = df_raw[available_columns].copy()\n",
    "    \n",
    "    print(f\"\\nSuccessfully dropped {len(columns_to_drop)} columns\")\n",
    "    print(f\"New dataset shape: {df_ml.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo columns need to be dropped - dataset already contains only ML features\")\n",
    "    df_ml = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34748d9",
   "metadata": {},
   "source": [
    "## Step 7: Clean Column Names and Ensure Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "813d12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All column names are already in proper snake_case format\n",
      "\n",
      "Final column names (25):\n",
      " 1. age\n",
      " 2. gender\n",
      " 3. blood_type\n",
      " 4. medical_condition\n",
      " 5. admission_type\n",
      " 6. length_of_stay_days\n",
      " 7. medication\n",
      " 8. test_results\n",
      " 9. insurance_provider\n",
      "10. billing_amount\n",
      "11. plan_type\n",
      "12. coverage_percentage\n",
      "13. max_coverage_amount\n",
      "14. copay_percentage\n",
      "15. deductible_amount\n",
      "16. annual_out_of_pocket_max\n",
      "17. excluded_conditions\n",
      "18. medication_coverage\n",
      "19. diagnostic_test_coverage\n",
      "20. admission_type_rules\n",
      "21. waiting_period\n",
      "22. pre_existing_condition_coverage\n",
      "23. network_coverage\n",
      "24. emergency_coverage\n",
      "25. preventive_care_coverage\n"
     ]
    }
   ],
   "source": [
    "# Function to convert column names to snake_case\n",
    "def to_snake_case(column_name):\n",
    "    \"\"\"\n",
    "    Convert column name to snake_case format.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Convert to lowercase and replace spaces/special chars with underscores\n",
    "    snake_case = re.sub(r'[\\s\\-\\.]+', '_', column_name.strip().lower())\n",
    "    \n",
    "    # Remove any double underscores\n",
    "    snake_case = re.sub(r'_+', '_', snake_case)\n",
    "    \n",
    "    # Remove leading/trailing underscores\n",
    "    snake_case = snake_case.strip('_')\n",
    "    \n",
    "    return snake_case\n",
    "\n",
    "# Store original column names for reference\n",
    "original_columns = df_ml.columns.tolist()\n",
    "\n",
    "# Apply snake_case conversion\n",
    "new_columns = [to_snake_case(col) for col in df_ml.columns]\n",
    "\n",
    "# Check if any changes are needed\n",
    "column_changes = [(orig, new) for orig, new in zip(original_columns, new_columns) if orig != new]\n",
    "\n",
    "if column_changes:\n",
    "    print(f\"Converting {len(column_changes)} column names to snake_case:\")\n",
    "    for orig, new in column_changes:\n",
    "        print(f\"   '{orig}' → '{new}'\")\n",
    "    \n",
    "    # Apply the changes\n",
    "    df_ml.columns = new_columns\n",
    "    print(\"\\nColumn names standardized to snake_case\")\n",
    "else:\n",
    "    print(\"All column names are already in proper snake_case format\")\n",
    "\n",
    "print(f\"\\nFinal column names ({len(df_ml.columns)}):\")\n",
    "for i, col in enumerate(df_ml.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce8a0d",
   "metadata": {},
   "source": [
    "## Step 8: Data Cleaning and Type Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2871817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DATA CLEANING PROCESS\n",
      "==================================================\n",
      "\n",
      "1. Handling Missing Values:\n",
      "   No missing values found\n",
      "\n",
      "2. Optimizing Data Types:\n",
      "   Memory usage: 255.60 MB → 158.81 MB (saved 96.80 MB)\n",
      "\n",
      "3. Checking for Duplicates:\n",
      "   Memory usage: 255.60 MB → 158.81 MB (saved 96.80 MB)\n",
      "\n",
      "3. Checking for Duplicates:\n",
      "   Removed 167034 duplicate rows\n",
      "\n",
      "Cleaning Summary:\n",
      "   Initial shape: (222000, 25)\n",
      "   Final shape: (54966, 25)\n",
      "   Rows removed: 167,034\n",
      "\n",
      "Cleaning Operations Performed:\n",
      "   1. Converted 'gender' to categorical (2 unique values)\n",
      "   2. Converted 'blood_type' to categorical (8 unique values)\n",
      "   3. Converted 'medical_condition' to categorical (6 unique values)\n",
      "   4. Converted 'admission_type' to categorical (3 unique values)\n",
      "   5. Converted 'medication' to categorical (5 unique values)\n",
      "   6. Converted 'test_results' to categorical (3 unique values)\n",
      "   7. Converted 'insurance_provider' to categorical (5 unique values)\n",
      "   8. Converted 'plan_type' to categorical (5 unique values)\n",
      "   9. Removed 167034 duplicate rows\n",
      "   Removed 167034 duplicate rows\n",
      "\n",
      "Cleaning Summary:\n",
      "   Initial shape: (222000, 25)\n",
      "   Final shape: (54966, 25)\n",
      "   Rows removed: 167,034\n",
      "\n",
      "Cleaning Operations Performed:\n",
      "   1. Converted 'gender' to categorical (2 unique values)\n",
      "   2. Converted 'blood_type' to categorical (8 unique values)\n",
      "   3. Converted 'medical_condition' to categorical (6 unique values)\n",
      "   4. Converted 'admission_type' to categorical (3 unique values)\n",
      "   5. Converted 'medication' to categorical (5 unique values)\n",
      "   6. Converted 'test_results' to categorical (3 unique values)\n",
      "   7. Converted 'insurance_provider' to categorical (5 unique values)\n",
      "   8. Converted 'plan_type' to categorical (5 unique values)\n",
      "   9. Removed 167034 duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data cleaning\n",
    "print(\"STARTING DATA CLEANING PROCESS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store initial state for comparison\n",
    "initial_shape = df_ml.shape\n",
    "cleaning_log = []\n",
    "\n",
    "# 1. Handle missing values\n",
    "print(\"\\n1. Handling Missing Values:\")\n",
    "missing_before = df_ml.isnull().sum().sum()\n",
    "\n",
    "if missing_before > 0:\n",
    "    print(f\"   Found {missing_before:,} missing values\")\n",
    "    \n",
    "    # Strategy for different column types\n",
    "    for col in df_ml.columns:\n",
    "        missing_count = df_ml[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            col_type = df_ml[col].dtype\n",
    "            \n",
    "            if col_type in ['object', 'string']:\n",
    "                # For categorical/text columns, fill with 'Unknown'\n",
    "                df_ml[col] = df_ml[col].fillna('Unknown')\n",
    "                cleaning_log.append(f\"Filled {missing_count} missing values in '{col}' with 'Unknown'\")\n",
    "                \n",
    "            elif col_type in ['int64', 'float64', 'int32', 'float32']:\n",
    "                # For numerical columns, fill with median\n",
    "                median_val = df_ml[col].median()\n",
    "                df_ml[col] = df_ml[col].fillna(median_val)\n",
    "                cleaning_log.append(f\"Filled {missing_count} missing values in '{col}' with median: {median_val}\")\n",
    "    \n",
    "    missing_after = df_ml.isnull().sum().sum()\n",
    "    print(f\"   Reduced missing values from {missing_before:,} to {missing_after:,}\")\n",
    "else:\n",
    "    print(\"   No missing values found\")\n",
    "\n",
    "# 2. Data type optimization\n",
    "print(\"\\n2. Optimizing Data Types:\")\n",
    "memory_before = df_ml.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "# Convert appropriate columns to categorical\n",
    "categorical_candidates = ['gender', 'blood_type', 'medical_condition', 'admission_type', \n",
    "                         'medication', 'test_results', 'insurance_provider', 'plan_type']\n",
    "\n",
    "for col in categorical_candidates:\n",
    "    if col in df_ml.columns and df_ml[col].dtype == 'object':\n",
    "        unique_count = df_ml[col].nunique()\n",
    "        total_count = len(df_ml[col])\n",
    "        \n",
    "        # Convert to categorical if it has reasonable number of unique values\n",
    "        if unique_count < total_count * 0.5:  # Less than 50% unique values\n",
    "            df_ml[col] = df_ml[col].astype('category')\n",
    "            cleaning_log.append(f\"Converted '{col}' to categorical ({unique_count} unique values)\")\n",
    "\n",
    "memory_after = df_ml.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"   Memory usage: {memory_before:.2f} MB → {memory_after:.2f} MB (saved {memory_before-memory_after:.2f} MB)\")\n",
    "\n",
    "# 3. Remove any potential duplicates\n",
    "print(\"\\n3. Checking for Duplicates:\")\n",
    "duplicates_count = df_ml.duplicated().sum()\n",
    "if duplicates_count > 0:\n",
    "    df_ml = df_ml.drop_duplicates()\n",
    "    cleaning_log.append(f\"Removed {duplicates_count} duplicate rows\")\n",
    "    print(f\"   Removed {duplicates_count} duplicate rows\")\n",
    "else:\n",
    "    print(\"   No duplicate rows found\")\n",
    "\n",
    "final_shape = df_ml.shape\n",
    "print(f\"\\nCleaning Summary:\")\n",
    "print(f\"   Initial shape: {initial_shape}\")\n",
    "print(f\"   Final shape: {final_shape}\")\n",
    "print(f\"   Rows removed: {initial_shape[0] - final_shape[0]:,}\")\n",
    "\n",
    "if cleaning_log:\n",
    "    print(f\"\\nCleaning Operations Performed:\")\n",
    "    for i, operation in enumerate(cleaning_log, 1):\n",
    "        print(f\"   {i}. {operation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4caafd",
   "metadata": {},
   "source": [
    "## Step 9: Save ML-Ready Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ece42555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ML-ready dataset to: /Users/kxshrx/asylum/healix/outputs/ml_outputs/final_ml_ready_claims.csv\n",
      "Successfully saved dataset!\n",
      "   File size: 24.59 MB\n",
      "   Location: /Users/kxshrx/asylum/healix/outputs/ml_outputs/final_ml_ready_claims.csv\n",
      "   Verification: Successfully read back 5 rows\n",
      "\n",
      "Metadata saved to: /Users/kxshrx/asylum/healix/outputs/ml_outputs/ml_data_preparation_metadata.json\n",
      "Successfully saved dataset!\n",
      "   File size: 24.59 MB\n",
      "   Location: /Users/kxshrx/asylum/healix/outputs/ml_outputs/final_ml_ready_claims.csv\n",
      "   Verification: Successfully read back 5 rows\n",
      "\n",
      "Metadata saved to: /Users/kxshrx/asylum/healix/outputs/ml_outputs/ml_data_preparation_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned ML-ready dataset\n",
    "try:\n",
    "    print(f\"Saving ML-ready dataset to: {output_file}\")\n",
    "    \n",
    "    # Save the main dataset\n",
    "    df_ml.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Verify the saved file\n",
    "    if output_file.exists():\n",
    "        file_size = output_file.stat().st_size / 1024**2  # Size in MB\n",
    "        print(f\"Successfully saved dataset!\")\n",
    "        print(f\"   File size: {file_size:.2f} MB\")\n",
    "        print(f\"   Location: {output_file}\")\n",
    "        \n",
    "        # Quick verification by reading back a few rows\n",
    "        verification_df = pd.read_csv(output_file, nrows=5)\n",
    "        print(f\"   Verification: Successfully read back {len(verification_df)} rows\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: File was not created successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create a metadata file with processing information\n",
    "metadata = {\n",
    "    'processing_timestamp': datetime.now().isoformat(),\n",
    "    'input_file': str(input_file),\n",
    "    'output_file': str(output_file),\n",
    "    'original_shape': initial_shape,\n",
    "    'final_shape': final_shape,\n",
    "    'columns_dropped': columns_to_drop,\n",
    "    'final_columns': df_ml.columns.tolist(),\n",
    "    'cleaning_operations': cleaning_log,\n",
    "    'memory_usage_mb': memory_after\n",
    "}\n",
    "\n",
    "metadata_file = ml_outputs_dir / 'ml_data_preparation_metadata.json'\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetadata saved to: {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b6a26",
   "metadata": {},
   "source": [
    "## Step 10: Final Summary and Sample Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af3e7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML DATA PREPARATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "FINAL DATASET SUMMARY:\n",
      "   Shape: 54,966 rows × 25 columns\n",
      "   Memory usage: 39.74 MB\n",
      "   Output location: /Users/kxshrx/asylum/healix/outputs/ml_outputs/final_ml_ready_claims.csv\n",
      "\n",
      "DROPPED COLUMNS (8):\n",
      "   ID columns: claim_id, provider_id, policy_id\n",
      "   Date/Time columns: discharge_date, created_at\n",
      "   Other columns: patient_hash, admission_year_month, data_source\n",
      "\n",
      "RETAINED ML FEATURES (25):\n",
      "   Demographics: age, gender, blood_type\n",
      "   Medical: medical_condition, medication, test_results\n",
      "   Admission: admission_type, length_of_stay_days\n",
      "   Insurance: insurance_provider, billing_amount, plan_type\n",
      "   Coverage: billing_amount, coverage_percentage, max_coverage_amount, copay_percentage, deductible_amount, medication_coverage, diagnostic_test_coverage, pre_existing_condition_coverage, network_coverage, emergency_coverage, preventive_care_coverage\n",
      "\n",
      "DATA QUALITY METRICS:\n",
      "   Missing values: 0 (0.00%)\n",
      "   Duplicate rows: 0\n",
      "   Categorical columns: 8\n",
      "   Numerical columns: 10\n",
      "\n",
      "SAMPLE DATA (First 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>medical_condition</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>length_of_stay_days</th>\n",
       "      <th>medication</th>\n",
       "      <th>test_results</th>\n",
       "      <th>insurance_provider</th>\n",
       "      <th>billing_amount</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>coverage_percentage</th>\n",
       "      <th>max_coverage_amount</th>\n",
       "      <th>copay_percentage</th>\n",
       "      <th>deductible_amount</th>\n",
       "      <th>annual_out_of_pocket_max</th>\n",
       "      <th>excluded_conditions</th>\n",
       "      <th>medication_coverage</th>\n",
       "      <th>diagnostic_test_coverage</th>\n",
       "      <th>admission_type_rules</th>\n",
       "      <th>waiting_period</th>\n",
       "      <th>pre_existing_condition_coverage</th>\n",
       "      <th>network_coverage</th>\n",
       "      <th>emergency_coverage</th>\n",
       "      <th>preventive_care_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>B-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Blue Cross</td>\n",
       "      <td>18856.281306</td>\n",
       "      <td>PPO Standard</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>Cosmetic surgery, Self-inflicted injuries, Exp...</td>\n",
       "      <td>Generic: $7.50 copay, Preferred brand: 30% coi...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Precertification required for inpatient stays,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nationwide PPO network with extensive provider...</td>\n",
       "      <td>Covered in and out of network, standard copays...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>A+</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>6</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>33643.327287</td>\n",
       "      <td>Original Medicare (Parts A &amp; B)</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>No limit</td>\n",
       "      <td>Cosmetic surgery, Routine dental/vision/hearin...</td>\n",
       "      <td>Part D separate - varies by plan, $2000 OOP ma...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Part A: $1676 deductible per benefit period, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Any Medicare-accepting provider nationwide</td>\n",
       "      <td>Covered nationwide and limited international</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>A-</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>15</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>27955.096079</td>\n",
       "      <td>Choice POS II Standard</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>20.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>Cosmetic treatments, Self-inflicted injuries, ...</td>\n",
       "      <td>Formulary-based tiered copays, Generic preferr...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Precertification required, Hospital copay per ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POS with large provider network, optional PCP</td>\n",
       "      <td>Covered in and out of network with standard co...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>O+</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Elective</td>\n",
       "      <td>30</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>37909.782410</td>\n",
       "      <td>Original Medicare (Parts A &amp; B)</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>No limit</td>\n",
       "      <td>Cosmetic surgery, Routine dental/vision/hearin...</td>\n",
       "      <td>Part D separate - varies by plan, $2000 OOP ma...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Part A: $1676 deductible per benefit period, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Any Medicare-accepting provider nationwide</td>\n",
       "      <td>Covered nationwide and limited international</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>Female</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>20</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>14238.317814</td>\n",
       "      <td>Choice POS II Standard</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>20.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>Cosmetic treatments, Self-inflicted injuries, ...</td>\n",
       "      <td>Formulary-based tiered copays, Generic preferr...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Precertification required, Hospital copay per ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POS with large provider network, optional PCP</td>\n",
       "      <td>Covered in and out of network with standard co...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender blood_type medical_condition admission_type  \\\n",
       "0   30    Male         B-            Cancer         Urgent   \n",
       "1   62    Male         A+           Obesity      Emergency   \n",
       "2   76  Female         A-           Obesity      Emergency   \n",
       "3   28  Female         O+          Diabetes       Elective   \n",
       "4   43  Female        AB+            Cancer         Urgent   \n",
       "\n",
       "   length_of_stay_days   medication  test_results insurance_provider  \\\n",
       "0                    2  Paracetamol        Normal         Blue Cross   \n",
       "1                    6    Ibuprofen  Inconclusive           Medicare   \n",
       "2                   15      Aspirin        Normal              Aetna   \n",
       "3                   30    Ibuprofen      Abnormal           Medicare   \n",
       "4                   20   Penicillin      Abnormal              Aetna   \n",
       "\n",
       "   billing_amount                        plan_type  coverage_percentage  \\\n",
       "0    18856.281306                     PPO Standard                 80.0   \n",
       "1    33643.327287  Original Medicare (Parts A & B)                 80.0   \n",
       "2    27955.096079           Choice POS II Standard                 80.0   \n",
       "3    37909.782410  Original Medicare (Parts A & B)                 80.0   \n",
       "4    14238.317814           Choice POS II Standard                 80.0   \n",
       "\n",
       "  max_coverage_amount  copay_percentage  deductible_amount  \\\n",
       "0           Unlimited              20.0             1500.0   \n",
       "1           Unlimited              20.0             1676.0   \n",
       "2           Unlimited              20.0              750.0   \n",
       "3           Unlimited              20.0             1676.0   \n",
       "4           Unlimited              20.0              750.0   \n",
       "\n",
       "  annual_out_of_pocket_max                                excluded_conditions  \\\n",
       "0                   8000.0  Cosmetic surgery, Self-inflicted injuries, Exp...   \n",
       "1                 No limit  Cosmetic surgery, Routine dental/vision/hearin...   \n",
       "2                   6500.0  Cosmetic treatments, Self-inflicted injuries, ...   \n",
       "3                 No limit  Cosmetic surgery, Routine dental/vision/hearin...   \n",
       "4                   6500.0  Cosmetic treatments, Self-inflicted injuries, ...   \n",
       "\n",
       "                                 medication_coverage  \\\n",
       "0  Generic: $7.50 copay, Preferred brand: 30% coi...   \n",
       "1  Part D separate - varies by plan, $2000 OOP ma...   \n",
       "2  Formulary-based tiered copays, Generic preferr...   \n",
       "3  Part D separate - varies by plan, $2000 OOP ma...   \n",
       "4  Formulary-based tiered copays, Generic preferr...   \n",
       "\n",
       "   diagnostic_test_coverage  \\\n",
       "0                      80.0   \n",
       "1                      80.0   \n",
       "2                     100.0   \n",
       "3                      80.0   \n",
       "4                     100.0   \n",
       "\n",
       "                                admission_type_rules  waiting_period  \\\n",
       "0  Precertification required for inpatient stays,...               0   \n",
       "1  Part A: $1676 deductible per benefit period, t...               0   \n",
       "2  Precertification required, Hospital copay per ...               0   \n",
       "3  Part A: $1676 deductible per benefit period, t...               0   \n",
       "4  Precertification required, Hospital copay per ...               0   \n",
       "\n",
       "   pre_existing_condition_coverage  \\\n",
       "0                                0   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "\n",
       "                                    network_coverage  \\\n",
       "0  Nationwide PPO network with extensive provider...   \n",
       "1         Any Medicare-accepting provider nationwide   \n",
       "2      POS with large provider network, optional PCP   \n",
       "3         Any Medicare-accepting provider nationwide   \n",
       "4      POS with large provider network, optional PCP   \n",
       "\n",
       "                                  emergency_coverage  preventive_care_coverage  \n",
       "0  Covered in and out of network, standard copays...                     100.0  \n",
       "1       Covered nationwide and limited international                     100.0  \n",
       "2  Covered in and out of network with standard co...                     100.0  \n",
       "3       Covered nationwide and limited international                     100.0  \n",
       "4  Covered in and out of network with standard co...                     100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COLUMN DATA TYPES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>54966</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_type</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_condition</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_type</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_stay_days</th>\n",
       "      <td>int64</td>\n",
       "      <td>54966</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medication</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_results</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_provider</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billing_amount</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plan_type</th>\n",
       "      <td>category</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_percentage</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_coverage_amount</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>copay_percentage</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deductible_amount</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_out_of_pocket_max</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excluded_conditions</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medication_coverage</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnostic_test_coverage</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_type_rules</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting_period</th>\n",
       "      <td>int64</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_existing_condition_coverage</th>\n",
       "      <td>int64</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network_coverage</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_coverage</th>\n",
       "      <td>object</td>\n",
       "      <td>54966</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preventive_care_coverage</th>\n",
       "      <td>float64</td>\n",
       "      <td>54966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Data Type  Non-Null Count  Unique Values\n",
       "age                                 int64           54966             77\n",
       "gender                           category           54966              2\n",
       "blood_type                       category           54966              8\n",
       "medical_condition                category           54966              6\n",
       "admission_type                   category           54966              3\n",
       "length_of_stay_days                 int64           54966             30\n",
       "medication                       category           54966              5\n",
       "test_results                     category           54966              3\n",
       "insurance_provider               category           54966              5\n",
       "billing_amount                    float64           54966          50000\n",
       "plan_type                        category           54966              5\n",
       "coverage_percentage               float64           54966              1\n",
       "max_coverage_amount                object           54966              1\n",
       "copay_percentage                  float64           54966              1\n",
       "deductible_amount                 float64           54966              4\n",
       "annual_out_of_pocket_max           object           54966              5\n",
       "excluded_conditions                object           54966              5\n",
       "medication_coverage                object           54966              5\n",
       "diagnostic_test_coverage          float64           54966              2\n",
       "admission_type_rules               object           54966              5\n",
       "waiting_period                      int64           54966              1\n",
       "pre_existing_condition_coverage     int64           54966              1\n",
       "network_coverage                   object           54966              5\n",
       "emergency_coverage                 object           54966              5\n",
       "preventive_care_coverage          float64           54966              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is now ready for ML modeling!\n",
      "All outputs saved in: /Users/kxshrx/asylum/healix/outputs/ml_outputs\n"
     ]
    }
   ],
   "source": [
    "# Print comprehensive final summary\n",
    "print(\"ML DATA PREPARATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nFINAL DATASET SUMMARY:\")\n",
    "print(f\"   Shape: {df_ml.shape[0]:,} rows × {df_ml.shape[1]} columns\")\n",
    "print(f\"   Memory usage: {df_ml.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"   Output location: {output_file}\")\n",
    "\n",
    "print(f\"\\nDROPPED COLUMNS ({len(columns_to_drop)}):\")\n",
    "if columns_to_drop:\n",
    "    # Group dropped columns by type for better readability\n",
    "    id_columns = [col for col in columns_to_drop if 'id' in col.lower()]\n",
    "    date_columns = [col for col in columns_to_drop if any(word in col.lower() for word in ['date', 'time', 'created'])]\n",
    "    other_columns = [col for col in columns_to_drop if col not in id_columns and col not in date_columns]\n",
    "    \n",
    "    if id_columns:\n",
    "        print(f\"   ID columns: {', '.join(id_columns)}\")\n",
    "    if date_columns:\n",
    "        print(f\"   Date/Time columns: {', '.join(date_columns)}\")\n",
    "    if other_columns:\n",
    "        print(f\"   Other columns: {', '.join(other_columns)}\")\n",
    "else:\n",
    "    print(\"   No columns were dropped\")\n",
    "\n",
    "print(f\"\\nRETAINED ML FEATURES ({len(df_ml.columns)}):\")\n",
    "feature_groups = {\n",
    "    'Demographics': ['age', 'gender', 'blood_type'],\n",
    "    'Medical': ['medical_condition', 'medication', 'test_results'],\n",
    "    'Admission': ['admission_type', 'length_of_stay_days'],\n",
    "    'Insurance': ['insurance_provider', 'billing_amount', 'plan_type'],\n",
    "    'Coverage': [col for col in df_ml.columns if 'coverage' in col or 'percentage' in col or 'amount' in col or 'deductible' in col]\n",
    "}\n",
    "\n",
    "for group_name, group_cols in feature_groups.items():\n",
    "    present_cols = [col for col in group_cols if col in df_ml.columns]\n",
    "    if present_cols:\n",
    "        print(f\"   {group_name}: {', '.join(present_cols)}\")\n",
    "\n",
    "print(f\"\\nDATA QUALITY METRICS:\")\n",
    "print(f\"   Missing values: {df_ml.isnull().sum().sum():,} ({(df_ml.isnull().sum().sum() / df_ml.size * 100):.2f}%)\")\n",
    "print(f\"   Duplicate rows: {df_ml.duplicated().sum():,}\")\n",
    "print(f\"   Categorical columns: {len([col for col in df_ml.columns if df_ml[col].dtype.name == 'category'])}\")\n",
    "print(f\"   Numerical columns: {len([col for col in df_ml.columns if df_ml[col].dtype.kind in 'biufc'])}\")\n",
    "\n",
    "print(f\"\\nSAMPLE DATA (First 5 rows):\")\n",
    "display(df_ml.head())\n",
    "\n",
    "print(f\"\\nCOLUMN DATA TYPES:\")\n",
    "dtype_info = df_ml.dtypes.to_frame('Data Type')\n",
    "dtype_info['Non-Null Count'] = df_ml.count()\n",
    "dtype_info['Unique Values'] = df_ml.nunique()\n",
    "display(dtype_info)\n",
    "\n",
    "print(f\"\\nDataset is now ready for ML modeling!\")\n",
    "print(f\"All outputs saved in: {ml_outputs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf86318",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Usage Notes and Next Steps\n",
    "\n",
    "### What This Notebook Accomplished\n",
    "\n",
    "1. **Data Loading**: Successfully loaded `outputs/claims_with_policy_rules.csv` with comprehensive error handling\n",
    "\n",
    "2. **Feature Selection**: Retained 26 carefully selected ML features covering:\n",
    "   - Patient demographics (age, gender, blood_type)\n",
    "   - Medical information (medical_condition, medication, test_results)\n",
    "   - Admission details (admission_type, length_of_stay_days)\n",
    "   - Insurance and billing (insurance_provider, billing_amount, plan_type)\n",
    "   - Policy coverage rules (13 coverage-related features)\n",
    "\n",
    "3. **Data Cleaning**: Applied comprehensive cleaning including:\n",
    "   - Standardized column names to snake_case\n",
    "   - Handled missing values with appropriate strategies\n",
    "   - Optimized data types for memory efficiency\n",
    "   - Removed duplicate rows\n",
    "\n",
    "4. **Output Management**: Saved clean dataset to `outputs/ml_outputs/final_ml_ready_claims.csv`\n",
    "\n",
    "### Files Created\n",
    "- `outputs/ml_outputs/final_ml_ready_claims.csv` - Main ML-ready dataset\n",
    "- `outputs/ml_outputs/ml_data_preparation_metadata.json` - Processing metadata and logs\n",
    "\n",
    "### Recommended Next Steps\n",
    "\n",
    "1. **Feature Engineering** (create `notebooks-02/feature_engineering.ipynb`):\n",
    "   - Create polynomial features\n",
    "   - Generate interaction terms\n",
    "   - Apply scaling/normalization\n",
    "   - Encode categorical variables\n",
    "\n",
    "2. **Exploratory Data Analysis** (create `notebooks-02/ml_eda.ipynb`):\n",
    "   - Statistical summaries of all features\n",
    "   - Correlation analysis\n",
    "   - Distribution plots\n",
    "   - Outlier detection\n",
    "\n",
    "3. **Model Training** (create `notebooks-02/model_training.ipynb`):\n",
    "   - Train/validation/test split\n",
    "   - Multiple algorithm comparison\n",
    "   - Cross-validation\n",
    "   - Hyperparameter tuning\n",
    "\n",
    "4. **Model Evaluation** (create `notebooks-02/model_evaluation.ipynb`):\n",
    "   - Performance metrics\n",
    "   - Feature importance analysis\n",
    "   - Model interpretability\n",
    "   - Prediction validation\n",
    "\n",
    "### Data Quality Assurance\n",
    "- All transformations are logged and reproducible  \n",
    "- Original data structure preserved in metadata  \n",
    "- Memory-optimized data types applied  \n",
    "- Consistent naming conventions enforced  \n",
    "- Missing value strategies documented  \n",
    "\n",
    "---\n",
    "\n",
    "*This notebook is part of the Healix ML pipeline. For questions or issues, refer to the metadata file or re-run this notebook with updated parameters.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
