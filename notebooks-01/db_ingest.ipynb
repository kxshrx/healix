{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2599d025",
   "metadata": {},
   "source": [
    "# Healthcare Claims Database Ingestion\n",
    "\n",
    "This notebook ingests the cleaned healthcare dataset into a SQLite database with a single `claims_table` for efficient storage and querying of healthcare claims data.\n",
    "\n",
    "## Process Overview:\n",
    "1. **Data Loading** - Load cleaned CSV from PHA scrubber\n",
    "2. **Database Creation** - Create SQLite database with claims_table schema\n",
    "3. **Claims Ingestion** - Bulk insert all healthcare claims with patient hashing\n",
    "4. **Performance Optimization** - Create indexes for efficient querying\n",
    "5. **Validation & Reporting** - Verify data integrity and generate summary report\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a626f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcare Claims Database Ingestion\n",
      "========================================\n",
      "Project root: /Users/kxshrx/asylum/healix\n",
      "Database directory: /Users/kxshrx/asylum/healix/db\n",
      "Target database: /Users/kxshrx/asylum/healix/db/claims_db.sqlite\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get project root directory (parent of notebooks-01)\n",
    "project_root = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "\n",
    "# Create database directory in project root\n",
    "db_dir = project_root / \"db\"\n",
    "db_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Healthcare Claims Database Ingestion\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Database directory: {db_dir.absolute()}\")\n",
    "print(f\"Target database: {db_dir / 'claims_db.sqlite'}\")\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4deadb",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Validation\n",
    "\n",
    "Load the cleaned healthcare dataset and perform initial validation to ensure data quality before database ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee5e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned dataset: /Users/kxshrx/asylum/healix/outputs/cleaned/healthcare_dataset_cleaned.csv\n",
      "==================================================\n",
      "Dataset loaded successfully:\n",
      "  Records: 55,500\n",
      "  Columns: 12\n",
      "  Required columns validated: ✓\n",
      "\n",
      "Dataset preview:\n",
      "   Age  Gender Blood Type Medical Condition Admission Type  \\\n",
      "0   30    Male         B-            Cancer         Urgent   \n",
      "1   62    Male         A+           Obesity      Emergency   \n",
      "2   76  Female         A-           Obesity      Emergency   \n",
      "3   28  Female         O+          Diabetes       Elective   \n",
      "4   43  Female        AB+            Cancer         Urgent   \n",
      "\n",
      "  admission_year_month  admission_year  length_of_stay_days   Medication  \\\n",
      "0              2024-01            2024                    2  Paracetamol   \n",
      "1              2019-08            2019                    6    Ibuprofen   \n",
      "2              2022-09            2022                   15      Aspirin   \n",
      "3              2020-11            2020                   30    Ibuprofen   \n",
      "4              2022-09            2022                   20   Penicillin   \n",
      "\n",
      "   Test Results Insurance Provider  Billing Amount  \n",
      "0        Normal         Blue Cross    18856.281306  \n",
      "1  Inconclusive           Medicare    33643.327287  \n",
      "2        Normal              Aetna    27955.096079  \n",
      "3      Abnormal           Medicare    37909.782410  \n",
      "4      Abnormal              Aetna    14238.317814  \n",
      "\n",
      "Data summary:\n",
      "  Unique insurance providers: 5\n",
      "  Date range: 2019-05 to 2024-05\n",
      "  Total billing amount: $1,417,432,043.40\n"
     ]
    }
   ],
   "source": [
    "def load_cleaned_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Load cleaned healthcare dataset with validation.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to cleaned CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Loaded and validated dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"Cleaned dataset not found: {file_path}\")\n",
    "        \n",
    "        # Load dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        print(f\"Dataset loaded successfully:\")\n",
    "        print(f\"  Records: {len(df):,}\")\n",
    "        print(f\"  Columns: {len(df.columns)}\")\n",
    "        \n",
    "        # Validate required columns for claims_table\n",
    "        required_cols = [\n",
    "            'Age', 'Gender', 'Blood Type', 'Medical Condition',\n",
    "            'Admission Type', 'admission_year_month', 'admission_year',\n",
    "            'length_of_stay_days', 'Medication', 'Test Results',\n",
    "            'Insurance Provider', 'Billing Amount'\n",
    "        ]\n",
    "        \n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        print(f\"  Required columns validated: ✓\")\n",
    "        \n",
    "        # Check for null values in critical fields\n",
    "        critical_fields = ['Insurance Provider', 'Billing Amount']\n",
    "        critical_nulls = df[critical_fields].isnull().sum()\n",
    "        if critical_nulls.any():\n",
    "            print(f\"  Warning: Null values in critical fields:\")\n",
    "            for col, null_count in critical_nulls.items():\n",
    "                if null_count > 0:\n",
    "                    print(f\"    {col}: {null_count} nulls\")\n",
    "        \n",
    "        # Data type validation\n",
    "        numeric_cols = ['Age', 'admission_year', 'length_of_stay_days', 'Billing Amount']\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "                print(f\"  Warning: {col} is not numeric type\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please ensure the PHA scrubbing process has been completed first.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load cleaned dataset - use relative path from project root\n",
    "cleaned_file = project_root / \"outputs\" / \"cleaned\" / \"healthcare_dataset_cleaned.csv\"\n",
    "print(f\"Loading cleaned dataset: {cleaned_file}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df_claims = load_cleaned_dataset(cleaned_file)\n",
    "\n",
    "if df_claims is not None:\n",
    "    print(f\"\\nDataset preview:\")\n",
    "    print(df_claims.head())\n",
    "    \n",
    "    print(f\"\\nData summary:\")\n",
    "    print(f\"  Unique insurance providers: {df_claims['Insurance Provider'].nunique()}\")\n",
    "    print(f\"  Date range: {df_claims['admission_year_month'].min()} to {df_claims['admission_year_month'].max()}\")\n",
    "    print(f\"  Total billing amount: ${df_claims['Billing Amount'].sum():,.2f}\")\n",
    "else:\n",
    "    print(\"Failed to load dataset. Stopping execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb110ec7",
   "metadata": {},
   "source": [
    "## 2. Database Schema Creation\n",
    "\n",
    "Create SQLite database with the claims_table schema optimized for healthcare claims storage and querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75776bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE SCHEMA CREATION\n",
      "==============================\n",
      "Creating database schema in: /Users/kxshrx/asylum/healix/db/claims_db.sqlite\n",
      "Database schema created successfully:\n",
      "  ✓ claims_table - Healthcare claims data with patient anonymization\n",
      "\n",
      "Created tables:\n",
      "  - claims_table\n",
      "  - sqlite_sequence\n",
      "  - sqlite_stat1\n",
      "  - sqlite_stat4\n",
      "  - policy_table\n",
      "  - claims_with_policy_rules\n",
      "\n",
      "Claims table schema:\n",
      "  claim_id (INTEGER)\n",
      "  patient_hash (TEXT)\n",
      "  age (INTEGER)\n",
      "  gender (TEXT)\n",
      "  blood_type (TEXT)\n",
      "  medical_condition (TEXT)\n",
      "  admission_year_month (TEXT)\n",
      "  admission_type (TEXT)\n",
      "  length_of_stay_days (INTEGER)\n",
      "  discharge_date (TEXT)\n",
      "  medication (TEXT)\n",
      "  test_results (TEXT)\n",
      "  insurance_provider (TEXT)\n",
      "  billing_amount (REAL)\n",
      "  created_at (TEXT)\n",
      "\n",
      "Initial database file size: 88132.00 KB\n"
     ]
    }
   ],
   "source": [
    "def create_claims_database(db_path):\n",
    "    \"\"\"\n",
    "    Create SQLite database with claims_table schema.\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path to SQLite database file\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: Database connection object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to database (creates file if doesn't exist)\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(f\"Creating database schema in: {db_path}\")\n",
    "        \n",
    "        # Claims table schema\n",
    "        claims_schema = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS claims_table (\n",
    "            claim_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            patient_hash TEXT,\n",
    "            age INTEGER,\n",
    "            gender TEXT,\n",
    "            blood_type TEXT,\n",
    "            medical_condition TEXT,\n",
    "            admission_year_month TEXT,\n",
    "            admission_type TEXT,\n",
    "            length_of_stay_days INTEGER,\n",
    "            discharge_date TEXT,\n",
    "            medication TEXT,\n",
    "            test_results TEXT,\n",
    "            insurance_provider TEXT,\n",
    "            billing_amount REAL,\n",
    "            created_at TEXT DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute schema creation\n",
    "        cursor.execute(claims_schema)\n",
    "        conn.commit()\n",
    "        \n",
    "        print(\"Database schema created successfully:\")\n",
    "        print(\"  ✓ claims_table - Healthcare claims data with patient anonymization\")\n",
    "        \n",
    "        return conn\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database schema: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create database and schema\n",
    "db_path = db_dir / \"claims_db.sqlite\"\n",
    "print(\"DATABASE SCHEMA CREATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "db_conn = create_claims_database(db_path)\n",
    "\n",
    "if db_conn:\n",
    "    # Verify table was created\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nCreated tables:\")\n",
    "    for table in tables:\n",
    "        print(f\"  - {table[0]}\")\n",
    "    \n",
    "    # Show table schema\n",
    "    cursor.execute(\"PRAGMA table_info(claims_table);\")\n",
    "    columns = cursor.fetchall()\n",
    "    print(f\"\\nClaims table schema:\")\n",
    "    for col in columns:\n",
    "        print(f\"  {col[1]} ({col[2]})\")\n",
    "    \n",
    "    print(f\"\\nInitial database file size: {db_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93e72e",
   "metadata": {},
   "source": [
    "## 3. Claims Data Ingestion\n",
    "\n",
    "Generate anonymous patient hashes and bulk insert all healthcare claims into the database using parameterized queries for security and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccc0eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAIMS DATA INGESTION\n",
      "=========================\n",
      "Generating anonymous patient hashes...\n",
      "Preparing data for database insertion...\n",
      "Preparing data for database insertion...\n",
      "Inserting 55,500 claims records...\n",
      "Inserting 55,500 claims records...\n",
      "Claims ingestion completed successfully:\n",
      "  Records inserted: 222,000\n",
      "  Unique patients: 55,500\n",
      "  Unique providers: 5\n",
      "  Unique conditions: 6\n",
      "  Total billing: $1,417,432,043.40\n",
      "  Average billing: $25,539.32\n",
      "  Date range: 2019-05 to 2024-05\n",
      "\n",
      "Sample claims records:\n",
      "  Claim 1: 4d68303a... | Cancer | Blue Cross | $18,856.28\n",
      "  Claim 2: ed9008fd... | Obesity | Medicare | $33,643.33\n",
      "  Claim 3: 5386d150... | Obesity | Aetna | $27,955.10\n",
      "Claims ingestion completed successfully:\n",
      "  Records inserted: 222,000\n",
      "  Unique patients: 55,500\n",
      "  Unique providers: 5\n",
      "  Unique conditions: 6\n",
      "  Total billing: $1,417,432,043.40\n",
      "  Average billing: $25,539.32\n",
      "  Date range: 2019-05 to 2024-05\n",
      "\n",
      "Sample claims records:\n",
      "  Claim 1: 4d68303a... | Cancer | Blue Cross | $18,856.28\n",
      "  Claim 2: ed9008fd... | Obesity | Medicare | $33,643.33\n",
      "  Claim 3: 5386d150... | Obesity | Aetna | $27,955.10\n"
     ]
    }
   ],
   "source": [
    "def generate_patient_hash(row):\n",
    "    \"\"\"\n",
    "    Generate anonymous patient hash from demographic data.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with patient data\n",
    "        \n",
    "    Returns:\n",
    "        str: SHA-256 hash for patient anonymization\n",
    "    \"\"\"\n",
    "    # Combine age, gender, blood type, and row index for unique but anonymous identifier\n",
    "    patient_data = f\"{row['Age']}_{row['Gender']}_{row['Blood Type']}_{row.name}\"\n",
    "    return hashlib.sha256(patient_data.encode()).hexdigest()[:16]\n",
    "\n",
    "def ingest_claims_data(df, conn):\n",
    "    \"\"\"\n",
    "    Bulk insert claims data into database.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Claims data to insert\n",
    "        conn: SQLite database connection\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ingestion statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"CLAIMS DATA INGESTION\")\n",
    "        print(\"=\" * 25)\n",
    "        \n",
    "        # Generate patient hashes for anonymization\n",
    "        print(\"Generating anonymous patient hashes...\")\n",
    "        df['patient_hash'] = df.apply(generate_patient_hash, axis=1)\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        print(\"Preparing data for database insertion...\")\n",
    "        \n",
    "        # Handle missing values and data cleaning\n",
    "        df_clean = df.copy()\n",
    "        df_clean = df_clean.fillna({\n",
    "            'admission_year_month': 'Unknown',\n",
    "            'length_of_stay_days': 0\n",
    "        })\n",
    "        \n",
    "        # Convert to appropriate types\n",
    "        df_clean['age'] = df_clean['Age'].astype(int)\n",
    "        df_clean['length_of_stay_days'] = df_clean['length_of_stay_days'].fillna(0).astype(int)\n",
    "        df_clean['billing_amount'] = df_clean['Billing Amount'].astype(float)\n",
    "        \n",
    "        # Create estimated discharge date from admission period and length of stay\n",
    "        df_clean['discharge_date'] = df_clean['admission_year_month'] + '-EST'\n",
    "        \n",
    "        # Prepare parameterized insertion query\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO claims_table (\n",
    "            patient_hash, age, gender, blood_type, medical_condition,\n",
    "            admission_year_month, admission_type, length_of_stay_days,\n",
    "            discharge_date, medication, test_results, insurance_provider,\n",
    "            billing_amount\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare data tuples for bulk insert\n",
    "        claims_data = []\n",
    "        for _, row in df_clean.iterrows():\n",
    "            claims_data.append((\n",
    "                row['patient_hash'],\n",
    "                row['age'],\n",
    "                row['Gender'],\n",
    "                row['Blood Type'],\n",
    "                row['Medical Condition'],\n",
    "                row['admission_year_month'],\n",
    "                row['Admission Type'],\n",
    "                row['length_of_stay_days'],\n",
    "                row['discharge_date'],\n",
    "                row['Medication'],\n",
    "                row['Test Results'],\n",
    "                row['Insurance Provider'],\n",
    "                row['billing_amount']\n",
    "            ))\n",
    "        \n",
    "        # Execute bulk insert with transaction\n",
    "        print(f\"Inserting {len(claims_data):,} claims records...\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.executemany(insert_query, claims_data)\n",
    "        conn.commit()\n",
    "        \n",
    "        # Verify insertion\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM claims_table\")\n",
    "        inserted_count = cursor.fetchone()[0]\n",
    "        \n",
    "        # Calculate ingestion statistics\n",
    "        stats = {\n",
    "            'total_records': len(df),\n",
    "            'inserted_records': inserted_count,\n",
    "            'unique_patients': df['patient_hash'].nunique(),\n",
    "            'unique_providers': df['Insurance Provider'].nunique(),\n",
    "            'unique_conditions': df['Medical Condition'].nunique(),\n",
    "            'total_billing': df['Billing Amount'].sum(),\n",
    "            'avg_billing': df['Billing Amount'].mean(),\n",
    "            'date_range': f\"{df['admission_year_month'].min()} to {df['admission_year_month'].max()}\",\n",
    "            'providers_list': sorted(df['Insurance Provider'].unique().tolist())\n",
    "        }\n",
    "        \n",
    "        print(f\"Claims ingestion completed successfully:\")\n",
    "        print(f\"  Records inserted: {stats['inserted_records']:,}\")\n",
    "        print(f\"  Unique patients: {stats['unique_patients']:,}\")\n",
    "        print(f\"  Unique providers: {stats['unique_providers']}\")\n",
    "        print(f\"  Unique conditions: {stats['unique_conditions']}\")\n",
    "        print(f\"  Total billing: ${stats['total_billing']:,.2f}\")\n",
    "        print(f\"  Average billing: ${stats['avg_billing']:,.2f}\")\n",
    "        print(f\"  Date range: {stats['date_range']}\")\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during claims ingestion: {e}\")\n",
    "        conn.rollback()\n",
    "        return None\n",
    "\n",
    "# Ingest claims data\n",
    "if df_claims is not None and db_conn:\n",
    "    ingestion_stats = ingest_claims_data(df_claims, db_conn)\n",
    "    \n",
    "    if ingestion_stats:\n",
    "        # Sample a few records to verify insertion\n",
    "        print(f\"\\nSample claims records:\")\n",
    "        cursor = db_conn.cursor()\n",
    "        cursor.execute(\"SELECT claim_id, patient_hash, medical_condition, insurance_provider, billing_amount FROM claims_table LIMIT 3\")\n",
    "        sample_records = cursor.fetchall()\n",
    "        \n",
    "        for record in sample_records:\n",
    "            print(f\"  Claim {record[0]}: {record[1][:8]}... | {record[2]} | {record[3]} | ${record[4]:,.2f}\")\n",
    "else:\n",
    "    print(\"Skipping claims ingestion due to previous errors\")\n",
    "    ingestion_stats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be5dd6",
   "metadata": {},
   "source": [
    "## 4. Performance Optimization\n",
    "\n",
    "Create database indexes on frequently queried columns to improve query performance for analytics and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e96388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING DATABASE INDEXES\n",
      "==============================\n",
      "  ✓ Created index: idx_insurance_provider\n",
      "  ✓ Created index: idx_patient_hash\n",
      "  ✓ Created index: idx_medical_condition\n",
      "  ✓ Created index: idx_admission_year_month\n",
      "  ✓ Created index: idx_billing_amount\n",
      "  ✓ Created index: idx_admission_type\n",
      "  ✓ Created index: idx_provider_condition\n",
      "  ✓ Created index: idx_provider_amount\n",
      "\n",
      "Index creation completed:\n",
      "  Indexes created: 8/8\n",
      "  Total custom indexes in database: 16\n",
      "  Database statistics updated for query optimization\n",
      "\n",
      "Database file size after indexing: 105376.00 KB\n",
      "  Database statistics updated for query optimization\n",
      "\n",
      "Database file size after indexing: 105376.00 KB\n"
     ]
    }
   ],
   "source": [
    "def create_database_indexes(conn):\n",
    "    \"\"\"\n",
    "    Create performance indexes on key columns.\n",
    "    \n",
    "    Args:\n",
    "        conn: SQLite database connection\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"CREATING DATABASE INDEXES\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Define indexes for optimal query performance\n",
    "        indexes = [\n",
    "            # Primary indexes for frequent lookups\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_insurance_provider ON claims_table(insurance_provider)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_patient_hash ON claims_table(patient_hash)\",\n",
    "            \n",
    "            # Secondary indexes for analytics\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_medical_condition ON claims_table(medical_condition)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_admission_year_month ON claims_table(admission_year_month)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_billing_amount ON claims_table(billing_amount)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_admission_type ON claims_table(admission_type)\",\n",
    "            \n",
    "            # Composite indexes for common query patterns\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_provider_condition ON claims_table(insurance_provider, medical_condition)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS idx_provider_amount ON claims_table(insurance_provider, billing_amount)\"\n",
    "        ]\n",
    "        \n",
    "        # Execute index creation\n",
    "        indexes_created = 0\n",
    "        for index_sql in indexes:\n",
    "            try:\n",
    "                cursor.execute(index_sql)\n",
    "                indexes_created += 1\n",
    "                # Extract index name for reporting\n",
    "                index_name = index_sql.split(\"idx_\")[1].split(\" \")[0]\n",
    "                print(f\"  ✓ Created index: idx_{index_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Failed to create index: {e}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"\\nIndex creation completed:\")\n",
    "        print(f\"  Indexes created: {indexes_created}/{len(indexes)}\")\n",
    "        \n",
    "        # Verify indexes exist\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='index' AND name LIKE 'idx_%'\")\n",
    "        db_indexes = cursor.fetchall()\n",
    "        \n",
    "        print(f\"  Total custom indexes in database: {len(db_indexes)}\")\n",
    "        \n",
    "        # Update database statistics for query optimization\n",
    "        cursor.execute(\"ANALYZE\")\n",
    "        conn.commit()\n",
    "        print(f\"  Database statistics updated for query optimization\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating indexes: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create database indexes\n",
    "if db_conn:\n",
    "    index_success = create_database_indexes(db_conn)\n",
    "    \n",
    "    if index_success:\n",
    "        # Check database size after indexing\n",
    "        db_size_after = db_path.stat().st_size\n",
    "        print(f\"\\nDatabase file size after indexing: {db_size_after / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(\"Skipping index creation due to database connection issues\")\n",
    "    index_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990958f8",
   "metadata": {},
   "source": [
    "## 5. Data Validation and Sample Queries\n",
    "\n",
    "Verify database integrity and demonstrate query capabilities with sample analytics queries to ensure the data was ingested correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72bf3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE VALIDATION AND SAMPLE QUERIES\n",
      "=============================================\n",
      "1. Database Overview:\n",
      "   Total claims: 222,000\n",
      "\n",
      "2. Data Quality Checks:\n",
      "   Claims with null insurance provider: 0\n",
      "   Claims with invalid billing amounts: 432\n",
      "   Unique patients (hashed): 55,500\n",
      "\n",
      "3. Insurance Provider Analysis:\n",
      "   Provider Summary:\n",
      "     Cigna: 44,996 claims, Avg: $25,525.77, Total: $1,148,557,381.07\n",
      "     Medicare: 44,616 claims, Avg: $25,615.99, Total: $1,142,883,032.50\n",
      "     UnitedHealthcare: 44,500 claims, Avg: $25,389.17, Total: $1,129,818,171.37\n",
      "     Blue Cross: 44,236 claims, Avg: $25,613.01, Total: $1,133,017,176.85\n",
      "     Aetna: 43,652 claims, Avg: $25,553.29, Total: $1,115,452,411.78\n",
      "\n",
      "4. Top Medical Conditions by Billing:\n",
      "     Diabetes: 37,216 cases, Avg: $25,638.41, Total: $954,158,901.97\n",
      "     Obesity: 36,924 cases, Avg: $25,805.97, Total: $952,859,682.77\n",
      "     Arthritis: 37,232 cases, Avg: $25,497.33, Total: $949,316,480.94\n",
      "     Hypertension: 36,980 cases, Avg: $25,497.10, Total: $942,882,601.23\n",
      "     Asthma: 36,740 cases, Avg: $25,635.25, Total: $941,839,061.44\n",
      "\n",
      "5. Monthly Admission Trends (Sample):\n",
      "     2019-05: 2,744 admissions, Avg: $25,733.45\n",
      "     2019-06: 3,628 admissions, Avg: $26,334.27\n",
      "     2019-07: 3,828 admissions, Avg: $25,884.60\n",
      "     2019-08: 4,004 admissions, Avg: $25,372.59\n",
      "     2019-09: 3,744 admissions, Avg: $24,929.57\n",
      "     2019-10: 4,052 admissions, Avg: $25,938.98\n",
      "     2019-11: 3,836 admissions, Avg: $25,844.12\n",
      "     2019-12: 3,712 admissions, Avg: $25,589.12\n"
     ]
    }
   ],
   "source": [
    "def validate_database_integrity(conn):\n",
    "    \"\"\"\n",
    "    Perform database validation and sample queries.\n",
    "    \n",
    "    Args:\n",
    "        conn: SQLite database connection\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"DATABASE VALIDATION AND SAMPLE QUERIES\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        validation_results = {}\n",
    "        \n",
    "        # 1. Basic table statistics\n",
    "        print(\"1. Database Overview:\")\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM claims_table\")\n",
    "        total_claims = cursor.fetchone()[0]\n",
    "        validation_results['total_claims'] = total_claims\n",
    "        print(f\"   Total claims: {total_claims:,}\")\n",
    "        \n",
    "        # 2. Data quality checks\n",
    "        print(f\"\\n2. Data Quality Checks:\")\n",
    "        \n",
    "        # Check for null values in critical fields\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM claims_table WHERE insurance_provider IS NULL\")\n",
    "        null_providers = cursor.fetchone()[0]\n",
    "        validation_results['null_providers'] = null_providers\n",
    "        print(f\"   Claims with null insurance provider: {null_providers}\")\n",
    "        \n",
    "        cursor.execute(\"SELECT COUNT(*) FROM claims_table WHERE billing_amount IS NULL OR billing_amount < 0\")\n",
    "        invalid_amounts = cursor.fetchone()[0]\n",
    "        validation_results['invalid_amounts'] = invalid_amounts\n",
    "        print(f\"   Claims with invalid billing amounts: {invalid_amounts}\")\n",
    "        \n",
    "        cursor.execute(\"SELECT COUNT(DISTINCT patient_hash) FROM claims_table\")\n",
    "        unique_patients = cursor.fetchone()[0]\n",
    "        validation_results['unique_patients'] = unique_patients\n",
    "        print(f\"   Unique patients (hashed): {unique_patients:,}\")\n",
    "        \n",
    "        # 3. Insurance provider analysis\n",
    "        print(f\"\\n3. Insurance Provider Analysis:\")\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT insurance_provider, \n",
    "                   COUNT(*) as claim_count,\n",
    "                   AVG(billing_amount) as avg_billing,\n",
    "                   SUM(billing_amount) as total_billing\n",
    "            FROM claims_table \n",
    "            GROUP BY insurance_provider \n",
    "            ORDER BY claim_count DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        provider_stats = cursor.fetchall()\n",
    "        validation_results['provider_analysis'] = provider_stats\n",
    "        \n",
    "        print(f\"   Provider Summary:\")\n",
    "        for provider, count, avg_bill, total_bill in provider_stats:\n",
    "            print(f\"     {provider}: {count:,} claims, Avg: ${avg_bill:,.2f}, Total: ${total_bill:,.2f}\")\n",
    "        \n",
    "        # 4. Medical condition analysis\n",
    "        print(f\"\\n4. Top Medical Conditions by Billing:\")\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT medical_condition,\n",
    "                   COUNT(*) as case_count,\n",
    "                   AVG(billing_amount) as avg_cost,\n",
    "                   SUM(billing_amount) as total_cost\n",
    "            FROM claims_table\n",
    "            GROUP BY medical_condition\n",
    "            ORDER BY total_cost DESC\n",
    "            LIMIT 5\n",
    "        \"\"\")\n",
    "        \n",
    "        condition_stats = cursor.fetchall()\n",
    "        validation_results['top_conditions'] = condition_stats\n",
    "        \n",
    "        for condition, count, avg_cost, total_cost in condition_stats:\n",
    "            print(f\"     {condition}: {count:,} cases, Avg: ${avg_cost:,.2f}, Total: ${total_cost:,.2f}\")\n",
    "        \n",
    "        # 5. Monthly admission trends\n",
    "        print(f\"\\n5. Monthly Admission Trends (Sample):\")\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT admission_year_month,\n",
    "                   COUNT(*) as admissions,\n",
    "                   AVG(billing_amount) as avg_billing\n",
    "            FROM claims_table\n",
    "            WHERE admission_year_month != 'Unknown'\n",
    "            GROUP BY admission_year_month\n",
    "            ORDER BY admission_year_month\n",
    "            LIMIT 8\n",
    "        \"\"\")\n",
    "        \n",
    "        monthly_trends = cursor.fetchall()\n",
    "        validation_results['monthly_trends'] = monthly_trends\n",
    "        \n",
    "        for month, admissions, avg_billing in monthly_trends:\n",
    "            print(f\"     {month}: {admissions:,} admissions, Avg: ${avg_billing:,.2f}\")\n",
    "        \n",
    "        return validation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during database validation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Validate database integrity\n",
    "if db_conn:\n",
    "    validation_results = validate_database_integrity(db_conn)\n",
    "else:\n",
    "    print(\"Skipping validation due to database connection issues\")\n",
    "    validation_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2664a",
   "metadata": {},
   "source": [
    "## 6. Generate Ingestion Report\n",
    "\n",
    "Create a comprehensive report summarizing the database ingestion process, statistics, and any warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6244aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING INGESTION REPORT\n",
      "==============================\n",
      "Report saved to: /Users/kxshrx/asylum/healix/db/db_ingest_report.txt\n",
      "\n",
      "REPORT SUMMARY:\n",
      "  Claims ingested: 222,000\n",
      "  Unique providers: 5\n",
      "  Database size: 105376.00 KB\n",
      "  Warnings: 1\n"
     ]
    }
   ],
   "source": [
    "def generate_ingestion_report(ingestion_stats, validation_results, output_path):\n",
    "    \"\"\"\n",
    "    Generate comprehensive database ingestion report.\n",
    "    \n",
    "    Args:\n",
    "        ingestion_stats (dict): Claims ingestion statistics\n",
    "        validation_results (dict): Database validation results\n",
    "        output_path (str): Path to save report file\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"GENERATING INGESTION REPORT\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # Get current database file size\n",
    "        db_size = db_path.stat().st_size / 1024  # KB\n",
    "        \n",
    "        # Create comprehensive report\n",
    "        report = f\"\"\"\n",
    "HEALTHCARE CLAIMS DATABASE INGESTION REPORT\n",
    "{'='*50}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Database: {db_path.absolute()}\n",
    "\n",
    "EXECUTIVE SUMMARY\n",
    "{'-'*20}\n",
    "✓ Database creation: SUCCESS\n",
    "✓ Schema deployment: SUCCESS (claims_table)\n",
    "✓ Claims data ingestion: {'SUCCESS' if ingestion_stats else 'FAILED'}\n",
    "✓ Index optimization: {'SUCCESS' if index_success else 'FAILED'}\n",
    "✓ Data validation: {'SUCCESS' if validation_results else 'FAILED'}\n",
    "\n",
    "DATABASE STATISTICS\n",
    "{'-'*20}\n",
    "Database File Size: {db_size:.2f} KB\n",
    "Table Created: claims_table\n",
    "\"\"\"\n",
    "\n",
    "        # Add ingestion statistics if available\n",
    "        if ingestion_stats:\n",
    "            report += f\"\"\"\n",
    "CLAIMS INGESTION RESULTS\n",
    "{'-'*25}\n",
    "Total Records Processed: {ingestion_stats['total_records']:,}\n",
    "Records Successfully Inserted: {ingestion_stats['inserted_records']:,}\n",
    "Unique Patients (Hashed): {ingestion_stats['unique_patients']:,}\n",
    "Unique Insurance Providers: {ingestion_stats['unique_providers']}\n",
    "Unique Medical Conditions: {ingestion_stats['unique_conditions']}\n",
    "Total Billing Amount: ${ingestion_stats['total_billing']:,.2f}\n",
    "Average Billing per Claim: ${ingestion_stats['avg_billing']:,.2f}\n",
    "Date Range: {ingestion_stats['date_range']}\n",
    "\n",
    "INSURANCE PROVIDERS FOUND:\n",
    "\"\"\"\n",
    "            for provider in ingestion_stats['providers_list']:\n",
    "                report += f\"  - {provider}\\n\"\n",
    "\n",
    "        # Add validation results if available\n",
    "        if validation_results:\n",
    "            report += f\"\"\"\n",
    "DATA VALIDATION RESULTS\n",
    "{'-'*23}\n",
    "Total Claims in Database: {validation_results.get('total_claims', 'N/A'):,}\n",
    "Unique Patients: {validation_results.get('unique_patients', 'N/A'):,}\n",
    "\n",
    "Data Quality Checks:\n",
    "- Claims with Null Insurance Providers: {validation_results.get('null_providers', 'N/A')}\n",
    "- Claims with Invalid Billing Amounts: {validation_results.get('invalid_amounts', 'N/A')}\n",
    "\n",
    "Top Medical Conditions by Total Billing:\n",
    "\"\"\"\n",
    "            # Add top conditions if available\n",
    "            if 'top_conditions' in validation_results:\n",
    "                for i, (condition, count, avg_cost, total_cost) in enumerate(validation_results['top_conditions'], 1):\n",
    "                    report += f\"  {i}. {condition}: {count:,} cases, Total: ${total_cost:,.2f}\\n\"\n",
    "\n",
    "        # Add database schema information\n",
    "        report += f\"\"\"\n",
    "DATABASE SCHEMA\n",
    "{'-'*15}\n",
    "Table: claims_table\n",
    "Purpose: Healthcare claims with patient demographics and billing information\n",
    "\n",
    "Columns:\n",
    "- claim_id: Primary key (auto-increment)\n",
    "- patient_hash: Anonymous patient identifier (SHA-256 hash)\n",
    "- age, gender, blood_type: Patient demographics\n",
    "- medical_condition: Primary diagnosis/condition\n",
    "- admission_year_month: Admission period (anonymized)\n",
    "- admission_type: Type of admission (Emergency, Urgent, Elective)\n",
    "- length_of_stay_days: Duration of stay\n",
    "- discharge_date: Estimated discharge period\n",
    "- medication, test_results: Treatment information\n",
    "- insurance_provider: Insurance company name\n",
    "- billing_amount: Total billing amount\n",
    "- created_at: Record creation timestamp\n",
    "\n",
    "INDEXES CREATED\n",
    "{'-'*15}\n",
    "Primary Indexes:\n",
    "- idx_insurance_provider: Fast provider lookups\n",
    "- idx_patient_hash: Patient-specific queries\n",
    "\n",
    "Secondary Indexes:\n",
    "- idx_medical_condition: Condition-based analysis\n",
    "- idx_admission_year_month: Temporal analysis\n",
    "- idx_billing_amount: Cost analysis\n",
    "- idx_admission_type: Admission type filtering\n",
    "\n",
    "Composite Indexes:\n",
    "- idx_provider_condition: Provider-condition analysis\n",
    "- idx_provider_amount: Provider billing analysis\n",
    "\"\"\"\n",
    "\n",
    "        # Add warnings and recommendations\n",
    "        warnings = []\n",
    "        recommendations = []\n",
    "        \n",
    "        if validation_results:\n",
    "            if validation_results.get('null_providers', 0) > 0:\n",
    "                warnings.append(f\"Found {validation_results['null_providers']} claims with null insurance providers\")\n",
    "            \n",
    "            if validation_results.get('invalid_amounts', 0) > 0:\n",
    "                warnings.append(f\"Found {validation_results['invalid_amounts']} claims with invalid billing amounts\")\n",
    "        \n",
    "        # Add recommendations\n",
    "        recommendations.extend([\n",
    "            \"Run VACUUM command periodically to optimize database file size\",\n",
    "            \"Consider adding additional indexes based on specific query patterns\",\n",
    "            \"Implement regular backup procedures for production use\",\n",
    "            \"Monitor query performance and add covering indexes for complex queries\",\n",
    "            \"Consider partitioning by admission_year_month for very large datasets\"\n",
    "        ])\n",
    "        \n",
    "        if warnings:\n",
    "            report += f\"\"\"\n",
    "WARNINGS\n",
    "{'-'*8}\n",
    "\"\"\"\n",
    "            for warning in warnings:\n",
    "                report += f\"⚠ {warning}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "RECOMMENDATIONS\n",
    "{'-'*15}\n",
    "\"\"\"\n",
    "        for rec in recommendations:\n",
    "            report += f\"• {rec}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "USAGE EXAMPLES\n",
    "{'-'*13}\n",
    "# Connect to database\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('{db_path}')\n",
    "\n",
    "# Example queries for analysis\n",
    "# 1. Claims by insurance provider\n",
    "provider_summary = pd.read_sql_query('''\n",
    "    SELECT insurance_provider, \n",
    "           COUNT(*) as total_claims,\n",
    "           AVG(billing_amount) as avg_billing,\n",
    "           SUM(billing_amount) as total_billing\n",
    "    FROM claims_table \n",
    "    GROUP BY insurance_provider \n",
    "    ORDER BY total_billing DESC\n",
    "''', conn)\n",
    "\n",
    "# 2. Most expensive medical conditions\n",
    "expensive_conditions = pd.read_sql_query('''\n",
    "    SELECT medical_condition,\n",
    "           COUNT(*) as case_count,\n",
    "           AVG(billing_amount) as avg_cost\n",
    "    FROM claims_table\n",
    "    GROUP BY medical_condition\n",
    "    ORDER BY avg_cost DESC\n",
    "    LIMIT 10\n",
    "''', conn)\n",
    "\n",
    "# 3. Monthly admission trends\n",
    "monthly_trends = pd.read_sql_query('''\n",
    "    SELECT admission_year_month,\n",
    "           COUNT(*) as admissions,\n",
    "           AVG(billing_amount) as avg_billing\n",
    "    FROM claims_table\n",
    "    WHERE admission_year_month != 'Unknown'\n",
    "    GROUP BY admission_year_month\n",
    "    ORDER BY admission_year_month\n",
    "''', conn)\n",
    "\n",
    "# 4. Patient claim history (using anonymous hash)\n",
    "patient_claims = pd.read_sql_query('''\n",
    "    SELECT claim_id, medical_condition, billing_amount, admission_year_month\n",
    "    FROM claims_table\n",
    "    WHERE patient_hash = 'specific_hash_value'\n",
    "    ORDER BY admission_year_month\n",
    "''', conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "END OF REPORT\n",
    "{'-'*13}\n",
    "Report generated by Healix Claims Database Ingestion Pipeline\n",
    "Database ready for healthcare analytics and claims processing.\n",
    "\"\"\"\n",
    "\n",
    "        # Save report to file\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"Report saved to: {output_path}\")\n",
    "        \n",
    "        # Print summary to console\n",
    "        print(f\"\\nREPORT SUMMARY:\")\n",
    "        if ingestion_stats:\n",
    "            print(f\"  Claims ingested: {ingestion_stats['inserted_records']:,}\")\n",
    "            print(f\"  Unique providers: {ingestion_stats['unique_providers']}\")\n",
    "        print(f\"  Database size: {db_size:.2f} KB\")\n",
    "        print(f\"  Warnings: {len(warnings)}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report: {e}\")\n",
    "        return False\n",
    "\n",
    "# Generate ingestion report\n",
    "report_path = db_dir / \"db_ingest_report.txt\"\n",
    "report_success = generate_ingestion_report(ingestion_stats, validation_results, report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53ba22",
   "metadata": {},
   "source": [
    "## 7. Cleanup and Final Output Summary\n",
    "\n",
    "Close database connections and provide final summary of all generated files and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b7a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINALIZING CLAIMS DATABASE INGESTION\n",
      "========================================\n",
      "✓ Database connection closed\n",
      "\n",
      "OUTPUT FILES VERIFICATION:\n",
      "  ✓ Database File: /Users/kxshrx/asylum/healix/db/claims_db.sqlite\n",
      "    Size: 105376.00 KB\n",
      "  ✓ Ingestion Report: /Users/kxshrx/asylum/healix/db/db_ingest_report.txt\n",
      "    Size: 4.57 KB\n",
      "\n",
      "FINAL STATUS:\n",
      "  Database Creation: ✓ SUCCESS\n",
      "  All Outputs Generated: ✓ YES\n",
      "\n",
      "DATABASE SUMMARY:\n",
      "  Claims ingested: 222,000\n",
      "  Insurance providers: 5\n",
      "  Total billing: $1,417,432,043.40\n",
      "  Database indexes: ✓ Created for performance\n",
      "\n",
      "NEXT STEPS:\n",
      "  1. Review ingestion report: /Users/kxshrx/asylum/healix/db/db_ingest_report.txt\n",
      "  2. Connect to database for analysis: /Users/kxshrx/asylum/healix/db/claims_db.sqlite\n",
      "  3. Run sample queries to explore the data\n",
      "  4. Consider adding policy_table and results_table for full claims processing\n",
      "  5. Implement backup procedures for production use\n",
      "\n",
      "CLAIMS DATABASE INGESTION COMPLETE\n",
      "Success: ✓\n"
     ]
    }
   ],
   "source": [
    "def finalize_ingestion():\n",
    "    \"\"\"\n",
    "    Finalize database ingestion process and cleanup resources.\n",
    "    \"\"\"\n",
    "    print(\"FINALIZING CLAIMS DATABASE INGESTION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Close database connection\n",
    "    if db_conn:\n",
    "        db_conn.close()\n",
    "        print(\"✓ Database connection closed\")\n",
    "    \n",
    "    # Verify all output files\n",
    "    outputs = {\n",
    "        'Database File': db_path,\n",
    "        'Ingestion Report': db_dir / \"db_ingest_report.txt\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nOUTPUT FILES VERIFICATION:\")\n",
    "    all_outputs_exist = True\n",
    "    \n",
    "    for output_name, output_path in outputs.items():\n",
    "        if output_path.exists():\n",
    "            size = output_path.stat().st_size\n",
    "            print(f\"  ✓ {output_name}: {output_path}\")\n",
    "            print(f\"    Size: {size / 1024:.2f} KB\")\n",
    "        else:\n",
    "            print(f\"  ✗ {output_name}: MISSING - {output_path}\")\n",
    "            all_outputs_exist = False\n",
    "    \n",
    "    # Final status\n",
    "    print(f\"\\nFINAL STATUS:\")\n",
    "    print(f\"  Database Creation: {'✓ SUCCESS' if db_path.exists() else '✗ FAILED'}\")\n",
    "    print(f\"  All Outputs Generated: {'✓ YES' if all_outputs_exist else '✗ NO'}\")\n",
    "    \n",
    "    # Database summary\n",
    "    if ingestion_stats:\n",
    "        print(f\"\\nDATABASE SUMMARY:\")\n",
    "        print(f\"  Claims ingested: {ingestion_stats['inserted_records']:,}\")\n",
    "        print(f\"  Insurance providers: {ingestion_stats['unique_providers']}\")\n",
    "        print(f\"  Total billing: ${ingestion_stats['total_billing']:,.2f}\")\n",
    "        print(f\"  Database indexes: ✓ Created for performance\")\n",
    "    \n",
    "    # Next steps\n",
    "    print(f\"\\nNEXT STEPS:\")\n",
    "    print(f\"  1. Review ingestion report: {db_dir / 'db_ingest_report.txt'}\")\n",
    "    print(f\"  2. Connect to database for analysis: {db_path}\")\n",
    "    print(f\"  3. Run sample queries to explore the data\")\n",
    "    print(f\"  4. Consider adding policy_table and results_table for full claims processing\")\n",
    "    print(f\"  5. Implement backup procedures for production use\")\n",
    "    \n",
    "    return all_outputs_exist\n",
    "\n",
    "# Finalize ingestion process\n",
    "ingestion_complete = finalize_ingestion()\n",
    "\n",
    "print(f\"\\nCLAIMS DATABASE INGESTION COMPLETE\")\n",
    "print(f\"Success: {'✓' if ingestion_complete else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73f3f7",
   "metadata": {},
   "source": [
    "## Final Output Summary\n",
    "\n",
    "### Generated Files:\n",
    "- **`db/claims_db.sqlite`** - SQLite database with healthcare claims\n",
    "- **`db/db_ingest_report.txt`** - Comprehensive ingestion report with statistics and usage examples\n",
    "\n",
    "### Database Structure:\n",
    "- **`claims_table`** - Complete healthcare claims with anonymous patient hashing\n",
    "  - 55,500 claims records with patient demographics and billing information\n",
    "  - Optimized indexes for efficient querying by provider, patient, condition, and billing amount\n",
    "  - Anonymous patient identification using SHA-256 hashing\n",
    "\n",
    "### Usage Notes:\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the claims database\n",
    "conn = sqlite3.connect('db/claims_db.sqlite')\n",
    "\n",
    "# Sample analytics queries\n",
    "# Total claims by insurance provider\n",
    "provider_analysis = pd.read_sql_query(\"\"\"\n",
    "    SELECT insurance_provider, COUNT(*) as claims, AVG(billing_amount) as avg_billing\n",
    "    FROM claims_table \n",
    "    GROUP BY insurance_provider \n",
    "    ORDER BY claims DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "# Most expensive medical conditions\n",
    "condition_costs = pd.read_sql_query(\"\"\"\n",
    "    SELECT medical_condition, COUNT(*) as cases, AVG(billing_amount) as avg_cost\n",
    "    FROM claims_table \n",
    "    GROUP BY medical_condition \n",
    "    ORDER BY avg_cost DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "conn.close()\n",
    "```\n",
    "\n",
    "**The healthcare claims database is now ready for analytics, reporting, and claims processing workflows!**\n",
    "\n",
    "For detailed usage examples and database schema information, refer to the generated ingestion report at `db/db_ingest_report.txt`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
